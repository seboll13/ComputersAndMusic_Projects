{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e39f30",
   "metadata": {},
   "source": [
    "## The following code uses the Pythonspaudiopy package\n",
    "- Docs: https://spaudiopy.readthedocs.io/en/latest/index.html\n",
    "- GitHub: https://github.com/chris-hld/spaudiopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1fa1cb",
   "metadata": {},
   "source": [
    "## Tools\n",
    "We use three parameters to locate an HRTF:\n",
    "1. *Azimuth*: angle between position and sound location on the $xy$-plane\n",
    "2. *Elevation*: angle between position and sound location on the $xz$-plane\n",
    "3. *Time* or *Frequency*: time period or frequency of emitted sound w.r.t. actual position\n",
    "\n",
    "Math tools:\n",
    "- *Haversine distance*: Consider two points $x_1$ and $x_2$ on a sphere with respective latitudes and longitudes $(\\varphi_1,\\varphi_2)$ and $(\\theta_1,\\theta_2)$. The Haversine distance $D(x_1,x_2)$ is the angular distance between them on the surface of the sphere given by $$D(x_1,x_2)=2\\arcsin\\sqrt{\\sin^2\\left(\\frac{\\varphi_2-\\varphi_1}{2}\\right)+\\cos x_1\\cos y_1\\sin^2\\left(\\frac{\\theta_2-\\theta_1}{2}\\right)}.$$ We use this distance when wanting to find the closest HRIR point from a grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18393aa4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check spaudiopy.sig functions to open MONO signal and play with HRIRs\n",
    "import spaudiopy as spa\n",
    "from spaudiopy.sig import MonoSignal as ms\n",
    "from spaudiopy.sig import MultiSignal as stereo \n",
    "import spaudiopy.process as sproc\n",
    "\n",
    "import scipy.signal\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "\n",
    "fs=44100 # sampling rate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3434822",
   "metadata": {},
   "source": [
    "## Test delay on stereo file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7793cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial test\n",
    "stereo_sample = stereo.from_file(\"ocean_eyes.wav\")\n",
    "s1, s2 = stereo_sample.get_signals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc31bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = np.zeros(len(stereo_sample), dtype=int)\n",
    "delay[int(fs*0.03)] = 1\n",
    "delayed_s2 = scipy.signal.convolve(s2, delay)[:len(stereo_sample)]\n",
    "delayed_stereo = stereo([s1, delayed_s2], fs=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(stereo_sample, rate=fs)) # original sample\n",
    "#display(Audio(delayed_stereo, rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd29bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stereo_tracks(music_file):\n",
    "    return stereo.from_file(music_file).get_signals()\n",
    "\n",
    "def delay_signal(s, delay):\n",
    "    _len_sample = len(s)\n",
    "    d_arr = np.zeros(_len_sample, dtype=int)\n",
    "    d_arr[int(fs*delay)] = 1\n",
    "    return scipy.signal.convolve(s, d_arr)[:_len_sample]\n",
    "\n",
    "def spatialize_signal(s, delay):\n",
    "    _len_sample = len(s)\n",
    "    d_arr = np.zeros(_len_sample, dtype=int)\n",
    "    d_arr[0] = 1\n",
    "    d_arr[int(fs*delay)] = 1\n",
    "    return scipy.signal.convolve(s, d_arr)[:_len_sample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4c054",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MS_DELAY = 25 # delay in [ms] to create surrounding effect\n",
    "\n",
    "def spatialise_sound_side(music_file, left=False):\n",
    "    \"\"\"Create a spatialised version of the given input file\n",
    "        @param music_file: stereo music file\n",
    "        @param left: creates the delay to the left or the right given this value\n",
    "    \"\"\"\n",
    "    s1,s2 = get_stereo_tracks(music_file)\n",
    "    if left:\n",
    "        delayed_s1 = delay_signal(s1, MS_DELAY / 1000)\n",
    "        return stereo([delayed_s1, s2], fs=fs)\n",
    "    delayed_s2 = delay_signal(s2, MS_DELAY / 1000)\n",
    "    return stereo([s1, delayed_s2], fs=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_left = spatialise_sound(\"ocean_eyes.wav\")\n",
    "s_left.save(\"ocean_eyes_spatialised.wav\")\n",
    "display(Audio(s_left, rate=fs))\n",
    "#s_right = spatialise_sound(\"ocean_eyes.wav\", True)\n",
    "#display(Audio(s_right, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b18698",
   "metadata": {},
   "source": [
    "## Reverb for increased spatial effect\n",
    "Create simultaneous small delay effects and combine them together in a new signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a41045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: WORK IN PROGRESS\n",
    "def reverb(music_file):\n",
    "    s1,s2 = get_stereo_tracks(music_file)\n",
    "    tracks = [s1]\n",
    "    for _ in range(5):\n",
    "        delayed_s2 = delay_signal(s2, 5 / 1000)\n",
    "        tracks.append(delayed_s2)\n",
    "        s2 = delayed_s2\n",
    "    return stereo(tracks, fs=fs)\n",
    "\n",
    "s_rev = reverb(\"ocean_eyes.wav\")\n",
    "display(Audio(s_rev, rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f64d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: WORK IN PROGRESS\n",
    "def echo(s):\n",
    "    _filter = [1]\n",
    "    for i in range(1, len(s)):\n",
    "        _filter.append(_filter[-1]*0.5)\n",
    "    return _filter\n",
    "\n",
    "def successive_echo(s):\n",
    "    _filter = [1]\n",
    "    for i in range(1, len(s)):\n",
    "        if i % fs/2 == 0:\n",
    "            _filter.append(1)\n",
    "        else:\n",
    "            _filter.append(_filter[-1]*0.99)\n",
    "    return _filter\n",
    "\n",
    "def successive_delays(s, delay):\n",
    "    return scipy.signal.convolve(s, echo(s))[:len(s)]\n",
    "\n",
    "def reverb_v2(music_file):\n",
    "    s1,s2 = get_stereo_tracks(music_file)\n",
    "    delayed_s1 = delay_signal(s1, MS_DELAY / 1000)\n",
    "    delayed_s2 = successive_delays(s2, MS_DELAY / 1000)\n",
    "    return stereo([s1, s2, delayed_s2], fs=fs)\n",
    "\n",
    "s_rev2 = reverb_v2(\"ocean_eyes.wav\")\n",
    "display(Audio(s_rev2, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd389b0",
   "metadata": {},
   "source": [
    "## Frequency plots\n",
    "We wish to visualise the main differences between the two frequency plots of both the original stereo file and the generated spatialised one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ab833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_freqs(wav_file, start, end):\n",
    "    fs, data = wavfile.read(wav_file)\n",
    "    data = data[:,0]\n",
    "    plt.figure()\n",
    "    data_to_plot = data[fs*start:fs*end]\n",
    "    plt.plot(data_to_plot)\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('Waveform of ' + wav_file)\n",
    "    plt.show()\n",
    "    return data_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ster = plot_freqs('ocean_eyes.wav', 30, 31)\n",
    "f_spat = plot_freqs('ocean_eyes_spatialised.wav', 30, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ee038",
   "metadata": {},
   "source": [
    "## Use of localisation cues\n",
    "Add direction to sound source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5637c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ear_distance = 0.21 # 21cm\n",
    "speed_of_sound = 343 # in m/s\n",
    "\n",
    "def fusion(s1, s2):\n",
    "    assert(len(s1) == len(s2))\n",
    "    return [s1[i]/2 + s2[i]/2 for i in range(len(s1))]\n",
    "\n",
    "def compute_delay_from_angle(rad):\n",
    "    return avg_ear_distance * np.sin(rad) / speed_of_sound\n",
    "\n",
    "def attenuate(sig, direction):\n",
    "    return [e*np.cos(direction/4) for e in sig]\n",
    "\n",
    "def localise_sound(stereo_music_file, direction, left=True):\n",
    "    \"\"\"Change location of the sound source\n",
    "        @param stereo_music_file: music file we wish to use\n",
    "        @param direction: where we want the sound to come from\n",
    "        @param left: False if we want the sound to come from the right, True o/wise\n",
    "    \"\"\"\n",
    "    s1,s2 = get_stereo_tracks(stereo_music_file)\n",
    "    sample_song_mono = fusion(s1, s2)\n",
    "    \n",
    "    maxmono = max(sample_song_mono)\n",
    "    _len_sample = len(sample_song_mono)\n",
    "    \n",
    "    mono_norm = [sample_song_mono[i]/(maxmono+1) for i in range(_len_sample)]\n",
    "    delayed = delay_signal(mono_norm, compute_delay_from_angle(direction))\n",
    "    \n",
    "    if left:\n",
    "        return stereo([mono_norm, attenuate(delayed, direction)], fs=fs) # sound to the left\n",
    "    return stereo([attenuate(delayed, direction), mono_norm], fs=fs) # sound to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_west = localise_sound(\"ocean_eyes.wav\", np.pi/2)\n",
    "display(Audio(s_west, rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_east = localise_sound(\"ocean_eyes.wav\", np.pi/2, False)\n",
    "display(Audio(s_east, rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e3555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORK IN PROGRESS\n",
    "def localise_spacialise_sound(music_file, direction, left=True):\n",
    "    s1,s2 = get_stereo_tracks(music_file)\n",
    "    sample_song_mono = fusion(s1, s2)\n",
    "    \n",
    "    maxmono = max(sample_song_mono)\n",
    "    _len_sample = len(sample_song_mono)\n",
    "    \n",
    "    mono_norm = [sample_song_mono[i]/(maxmono+1) for i in range(_len_sample)]\n",
    "    angle = compute_delay_from_angle(direction)\n",
    "    delayed = delay_signal(attenuate(mono_norm, angle), angle)\n",
    "        \n",
    "    mono_norm_spazialized = spatialize_signal(mono_norm, MS_DELAY / 1000)\n",
    "    delayed_spazialized = spatialize_signal(delayed, MS_DELAY / 1000) \n",
    "    \n",
    "    if left: \n",
    "        return stereo([mono_norm_spazialized, delayed_spazialized], fs=fs)\n",
    "    return stereo([delayed_spazialized, mono_norm_spazialized], fs=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbfdbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = localise_spacialise_sound(\"ocean_eyes.wav\", np.pi/2, False)\n",
    "display(Audio(sound, rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82085ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = localise_spacialise_sound(\"ocean_eyes.wav\", np.pi/2, True)\n",
    "display(Audio(sound, rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b05c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
