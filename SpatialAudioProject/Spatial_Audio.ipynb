{
    "cells": [{
            "cell_type": "markdown",
            "id": "d6e39f30",
            "metadata": {},
            "source": [
                "## Basic code using spaudiopy package\n",
                "- Docs: https://spaudiopy.readthedocs.io/en/latest/index.html\n",
                "- GitHub: https://github.com/chris-hld/spaudiopy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "88ad10ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check spaudiopy.sig functions to open MONO signal and play with HRIRs\n",
                "import spaudiopy as spa\n",
                "from spaudiopy.sig import MonoSignal as ms\n",
                "from spaudiopy.sig import MultiSignal as stereo \n",
                "import spaudiopy.process as sproc\n",
                "\n",
                "import scipy.signal\n",
                "from scipy.io import wavfile\n",
                "from IPython.display import Audio\n",
                "\n",
                "fs=44100 # sampling rate\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6d1fa1cb",
            "metadata": {},
            "source": [
                "## Tools\n",
                "We use three parameters to locate an HRTF:\n",
                "1. *Azimuth*: angle between position and sound location on the $xy$-plane\n",
                "2. *Elevation*: angle between position and sound location on the $xz$-plane\n",
                "3. *Time* or *Frequency*: time period or frequency of emitted sound w.r.t. actual position\n",
                "\n",
                "Math tools:\n",
                "- *Haversine distance*: Consider two points $x_1$ and $x_2$ on a sphere with respective latitudes and longitudes $(\\varphi_1,\\varphi_2)$ and $(\\theta_1,\\theta_2)$. The Haversine distance $D(x_1,x_2)$ is the angular distance between them on the surface of the sphere given by $$D(x_1,x_2)=2\\arcsin\\sqrt{\\sin^2\\left(\\frac{\\varphi_2-\\varphi_1}{2}\\right)+\\cos x_1\\cos y_1\\sin^2\\left(\\frac{\\theta_2-\\theta_1}{2}\\right)}.$$ We use this distance when wanting to find the closest HRIR point from a grid."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "15929605",
            "metadata": {},
            "outputs": [],
            "source": [
                "piano_test = ms.from_file(\"piano_testfile.wav\")\n",
                "piano_test.trim(0,3)\n",
                "#piano_test.play()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b3434822",
            "metadata": {},
            "source": [
                "## Test delay on stereo file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7793cb0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initial test\n",
                "stereo_sample = stereo.from_file(\"ocean_eyes.wav\")\n",
                "s1, s2 = stereo_sample.get_signals()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9dc31bdc",
            "metadata": {},
            "outputs": [],
            "source": [
                "delay = np.zeros(len(stereo_sample), dtype=int)\n",
                "delay[int(fs*0.03)] = 1\n",
                "delayed_s2 = scipy.signal.convolve(s2, delay)[:len(stereo_sample)]\n",
                "delayed_stereo = stereo([s1, delayed_s2], fs=fs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b43b9c9",
            "metadata": {},
            "outputs": [],
            "source": [
                "display(Audio(stereo_sample, rate=fs)) # original sample\n",
                "#display(Audio(delayed_stereo, rate=fs))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fbd29bec",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_stereo_tracks(music_file):\n",
                "    sample = stereo.from_file(music_file)\n",
                "    return sample.get_signals()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50c4c054",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "MS_DELAY = 25 # delay in [ms] to create surrounding effect\n",
                "\n",
                "def delay_signal(s1, s2):\n",
                "    assert(len(s1) == len(s2))\n",
                "    _len_sample = len(s1)\n",
                "    delay = np.zeros(_len_sample, dtype=int)\n",
                "    delay[int(fs*MS_DELAY / 1000)] = 1\n",
                "    return scipy.signal.convolve(s2, delay)[:_len_sample]\n",
                "\n",
                "def spatialise_sound(music_file, left=False):\n",
                "    s1,s2 = get_stereo_tracks(music_file)\n",
                "    if left:\n",
                "        delayed_s1 = delay_signal(s2, s1)\n",
                "        return stereo([delayed_s1, s2], fs=fs)\n",
                "    delayed_s2 = delay_signal(s1, s2)\n",
                "    return stereo([s1, delayed_s2], fs=fs)\n",
                "\n",
                "s_left = spatialise_sound(\"ocean_eyes.wav\", True)\n",
                "display(Audio(s_left, rate=fs))\n",
                "#s_right = spatialise_sound(\"ocean_eyes.wav\", False)\n",
                "#display(Audio(s_right, rate=fs))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "125ee038",
            "metadata": {},
            "source": [
                "## Use of localisation cues"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aa5637c1",
            "metadata": {},
            "outputs": [],
            "source": [
                "avg_ear_distance = 0.21 # 21cm\n",
                "speed_of_sound = 343 # in m/s\n",
                "\n",
                "def fusion(s1, s2):\n",
                "    assert(len(s1) == len(s2))\n",
                "    s = []\n",
                "    for i in range(len(s1)):\n",
                "        s.append(s1[i]/2 + s2[i]/2)\n",
                "    return s\n",
                "\n",
                "def compute_delay_from_angle(rad):\n",
                "    return avg_ear_distance * np.sin(rad) / speed_of_sound\n",
                "\n",
                "def attenuate(sig, direction):\n",
                "    return [e*np.cos(direction/4) for e in sig]\n",
                "\n",
                "def localise_sound(stereo_music_file, direction, left=True):\n",
                "    \"\"\"Change location of the sound source\n",
                "        @param stereo_music_file: music file we wish to use\n",
                "        @param direction: where we want the sound to come from\n",
                "        @param left: False if we want the sound to come from the right, True o/wise\n",
                "    \"\"\"\n",
                "    s1,s2 = get_stereo_tracks(music_file)\n",
                "    \n",
                "    sample_song_mono = fusion(s1, s2)\n",
                "    maxmono = max(sample_song_mono)\n",
                "    mono_norm = []\n",
                "    for i in range(len(sample_song_mono)):\n",
                "        mono_norm.append(sample_song_mono[i]/(maxmono+1))\n",
                "        \n",
                "    delay = np.zeros(len(mono_norm), dtype=int)\n",
                "    delay[int(fs*compute_delay_from_angle(direction))] = 1\n",
                "    delayed = scipy.signal.convolve(mono_norm, delay)[:len(mono_norm)]\n",
                "    \n",
                "    if left:\n",
                "        return stereo([mono_norm, attenuate(delayed, direction)], fs=fs) # sound to the left\n",
                "    return stereo([attenuate(delayed, direction), mono_norm], fs=fs) # sound to the right"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d798eed5",
            "metadata": {},
            "outputs": [],
            "source": [
                "s_west = localise_sound(\"ocean_eyes.wav\", np.pi/2)\n",
                "display(Audio(s_ww, rate=fs))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a720647d",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}